{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi2aH1D5gTp7",
        "outputId": "34748189-c4ff-49a1-ba50-01b4a2893275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting uts\n",
            "  Downloading uts-0.0.4.tar.gz (5.4 kB)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from uts) (1.19.5)\n",
            "Building wheels for collected packages: uts\n",
            "  Building wheel for uts (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uts: filename=uts-0.0.4-py3-none-any.whl size=6678 sha256=abf330eff1ce6f61acaffd382c72827255077861769c825d33c6d4f83ee6be9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/71/ba/61ac322199ea88f9cd28b710ac1bef6c821e1ac71a635104fc\n",
            "Successfully built uts\n",
            "Installing collected packages: uts\n",
            "Successfully installed uts-0.0.4\n"
          ]
        }
      ],
      "source": [
        "%pip install uts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rsQV8Fxpz1V"
      },
      "outputs": [],
      "source": [
        "import uts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0g11Tx1JqMut"
      },
      "outputs": [],
      "source": [
        "mylines = []                             # Declare an empty list named mylines.\n",
        "with open ('script.txt', 'rt') as myfile: # Open lorem.txt for reading text data.\n",
        "    for myline in myfile:                # For each line, stored as myline,\n",
        "        mylines.append(myline)           # add its contents to mylines.\n",
        "mydialogue = []\n",
        "for i in range(len(mylines)):\n",
        "    if len(mylines[i])- len(mylines[i].lstrip())>9:\n",
        "        mydialogue.append(mylines[i])\n",
        "\n",
        "mydial = ''.join(mydialogue)\n",
        "dial = mydial.split('                     ')\n",
        "dialogue = [s.replace(\"\\n\", \"\") for s in dial]\n",
        "dialoguetot = []\n",
        "for i in range (len(dialogue)):\n",
        "    dialogue_i = []\n",
        "    dialogue_i.append(dialogue[i])\n",
        "    dialoguetot.append(dialogue_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wg_zZmz579-"
      },
      "outputs": [],
      "source": [
        "# this is to take out all empty strings from the dialogue \n",
        "realdialogue = [] \n",
        "for i in range (len(dialoguetot)):\n",
        "  if any(c.isalpha() for c in dialoguetot[i][0]) == True:\n",
        "    realdialogue.append(dialoguetot[i])\n",
        "  else : \n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is to block our sentences into group of conversations\n",
        "conv = [realdialogue[0]]\n",
        "conv1 = []\n",
        "for i in range (1, len(realdialogue)):\n",
        "  if i % 10 == 0:\n",
        "    conv1.append(realdialogue[i])\n",
        "    conv.append(conv1)\n",
        "    conv1 = []\n",
        "  else :\n",
        "    conv1.append(realdialogue[i])\n",
        "\n",
        "# And this to make list of lists \n",
        "realconv =[]\n",
        "for i in range(0, len(conv)):\n",
        "  flat_conv = []\n",
        "  for sublist in conv[i]:\n",
        "    for item in sublist:\n",
        "        flat_conv.append(item)\n",
        "  realconv.append(flat_conv)"
      ],
      "metadata": {
        "id": "TEjagXUkEA0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell is for the test where I divide script in 3 parts \n",
        "import math\n",
        "n = len(realdialogue)\n",
        "conv1 = []\n",
        "conv2 = []\n",
        "conv3 = []\n",
        "for i in range(0,math.ceil(n/3)):\n",
        "  conv1.append(realdialogue[i])\n",
        "for i in range(math.ceil(n/3), math.ceil((2*n)/3)):\n",
        "  conv2.append(realdialogue[i])\n",
        "for i in range(math.ceil((2*n)/3),n):\n",
        "  conv3.append(realdialogue[i])\n",
        "conv = [conv1,conv2,conv3]\n",
        "\n",
        "#to make it list of lists it does not change\n",
        "realconv =[]\n",
        "for i in range(0, len(conv)):\n",
        "  flat_conv = []\n",
        "  for sublist in conv[i]:\n",
        "    for item in sublist:\n",
        "        flat_conv.append(item)\n",
        "  realconv.append(flat_conv)"
      ],
      "metadata": {
        "id": "4-h-IYTbUXX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(realconv[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPK96B3hG4Gm",
        "outputId": "f1e14152-f5d3-4a97-8331-e9d5fec8f5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "234"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Og9scdBXpz1Y"
      },
      "outputs": [],
      "source": [
        "import gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mweLiI56ly2v"
      },
      "outputs": [],
      "source": [
        "# I modify the remove name function from the original one to adapt to my script and what I do \n",
        "# Is that I use the fact that each dialogue starts with the name then many spaces so I take this part out\n",
        "# this is for the case where I have one big list \n",
        "def remove_name2(conversation):\n",
        "  paroles = []\n",
        "  for i in range(0, len(conversation)):\n",
        "    newdialogue = conversation[i][0].split('   ')\n",
        "    for i in range (0,len(newdialogue)):\n",
        "      if newdialogue[i].isupper() == False :\n",
        "        paroles.append(newdialogue[i])\n",
        "  return paroles\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove name test when I divide into list of lists \n",
        "def remove_name3(conversation):\n",
        "  paroles = []\n",
        "  for i in range(0, len(conversation)):\n",
        "    newdialogue = conversation[i].split('       ')\n",
        "    for i in range (0,len(newdialogue)):\n",
        "      if newdialogue[i].isupper() == False :\n",
        "        paroles.append(newdialogue[i])\n",
        "  return paroles"
      ],
      "metadata": {
        "id": "2vxACYkREcN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7jT2adIpz1Y"
      },
      "outputs": [],
      "source": [
        "# Original remove name function that is now unused\n",
        "def remove_name(s):\n",
        "    temp = \"\"\n",
        "    flag = 0\n",
        "    for i in range(0, len(s)):\n",
        "        if s[i] == ':':\n",
        "            flag = 1\n",
        "            continue\n",
        "        if flag == 1:\n",
        "            temp += s[i]\n",
        "    return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "28ilztT7pz1Z",
        "outputId": "2c5d117e-d5a1-47c6-b33d-712a67355eb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1ac6bbe9be0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mphrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_name3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrealconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mtemp_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphrases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-31384e2aecab>\u001b[0m in \u001b[0;36mremove_name3\u001b[0;34m(conversation)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mparoles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnewdialogue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'       '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewdialogue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mnewdialogue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
          ]
        }
      ],
      "source": [
        "# I modified this cell a little from original because my remove name function directly returns a list with all sentences said \n",
        "# this one is for the case where we have one list with all sentences\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "sentences = []\n",
        "phrases = remove_name2(realdialogue)\n",
        "for i in range(0, len(phrases)):\n",
        "      temp_sent = phrases[i]\n",
        "      tokens = word_tokenize(temp_sent)\n",
        "      tokens = [w.lower() for w in tokens]\n",
        "      stripped = [w.translate(table) for w in tokens]\n",
        "      sentences.append(stripped)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is for the case -where we have a list of lists of sentences\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "sentences = []\n",
        "for i in range (0, len(realconv)):\n",
        "      phrases = remove_name3(realconv[i])\n",
        "      for j in range(0,len(phrases)):\n",
        "        temp_sent = phrases[j]\n",
        "        tokens = word_tokenize(temp_sent)\n",
        "        tokens = [w.lower() for w in tokens]\n",
        "        stripped = [w.translate(table) for w in tokens]\n",
        "        sentences.append(stripped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ob22fuZFESQ",
        "outputId": "59c273e8-8415-4916-8469-f1cfd83ff8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL4Rh5zFX8Nf",
        "outputId": "e65fa297-e956-4517-c737-f8a5d3d4108f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['by'],\n",
              " [],\n",
              " ['david', 'franzoni'],\n",
              " [],\n",
              " ['revised', 'by', 'john', 'logan'],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " ['october', '22', '', '1998'],\n",
              " ['', 'while', 'stands', 'the', 'colosseum', '', 'rome', 'shall', 'stand', ''],\n",
              " ['when', 'falls', 'the', 'colosseum', '', 'rome', 'shall', 'fall', ''],\n",
              " ['and', 'when', 'rome', 'falls', '', 'the', 'world', '', ''],\n",
              " [],\n",
              " [],\n",
              " ['byron'],\n",
              " ['do', 'you', 'think', 'he', 's', 'really', 'dying', ''],\n",
              " ['he', 's', 'been', 'dying', 'for', 'ten', 'years', ''],\n",
              " ['i', 'think', 'he', 's', 'really', 'dying', 'this', 'time', ''],\n",
              " ['he', 'has', 'to', 'be', 'bled', 'every', 'night', 'now', ''],\n",
              " ['how', 'do', 'you', 'know', 'that', ''],\n",
              " ['i', 've', 'been', 'so', 'informed', ''],\n",
              " ['if', 'he', 'were', 'nt', 'really', 'dying', 'he'],\n",
              " ['would', 'nt', 'have', 'sent', 'for', 'us', ''],\n",
              " [],\n",
              " ['', 'a', 'smile', ''],\n",
              " ['maybe', 'he', 'just', 'misses', 'us', ''],\n",
              " ['and', 'the', 'senators', '', 'he', 'would', 'nt', 'have'],\n",
              " ['summoned', 'them', 'if', ''],\n",
              " ['peace', '', 'commodus', '', 'after', 'two', 'weeks', 'on'],\n",
              " ['the', 'road', 'your', 'incessant', 'scheming', 'is'],\n",
              " ['hurting', 'my', 'head', ''],\n",
              " ['the', 'first', 'thing', 'i', 'shall', 'do', 'is', 'honor'],\n",
              " ['him', 'with', 'games', 'worthy', 'of', 'his'],\n",
              " ['majesty', ''],\n",
              " ['the', 'first', 'thing', 'i', 'shall', 'do', 'is', 'have', 'a'],\n",
              " ['hot', 'bath', ''],\n",
              " ['why', 'have', 'we', 'stopped', ''],\n",
              " ['we', 're', 'here', '', 'sir', ''],\n",
              " [],\n",
              " ['', 'to', 'soldier', '', '1', ''],\n",
              " ['where', 'is', 'my', 'father', ''],\n",
              " ['he', 's', 'at', 'the', 'front', '', 'sir', ''],\n",
              " ['is', 'the', 'battle', 'won', ''],\n",
              " ['do', 'nt', 'know', '', 'sir', '', 'they', 've', 'been', 'gone'],\n",
              " ['for', 'eight', 'days', ''],\n",
              " [],\n",
              " ['', 'to', 'soldier', '', '1', ''],\n",
              " ['my', 'sister', 'wants', 'a', 'bath', '', 'take', 'her', 'to'],\n",
              " ['the', 'camp', ''],\n",
              " [],\n",
              " ['', 'to', 'soldier', '', '2', ''],\n",
              " ['take', 'me', 'to', 'my', 'father', ''],\n",
              " [],\n",
              " ['', 'dry', ''],\n",
              " ['civilization', 'at', 'last', '', 'gods', 'preserve'],\n",
              " ['us', ''],\n",
              " ['you', 'would', 'do', 'as', 'well', 'to', 'read', 'the'],\n",
              " ['mind', 'of', 'a', 'rhinoceros', ''],\n",
              " ['these', 'barbarians', 'would', 'rather', 'drown'],\n",
              " ['in', 'blood', 'than', 'yield', 'an', 'inch', '', 'if', 'i'],\n",
              " ['did', 'nt', 'hate', 'them', 'so', 'much', 'i', 'would'],\n",
              " ['admire', 'them', ''],\n",
              " ['they', 'simply', 'will', 'not', 'surrender', ''],\n",
              " [],\n",
              " ['', 'quietly', ''],\n",
              " ['a', 'people', 'should', 'know', 'when', 'they', 'are'],\n",
              " ['conquered', ''],\n",
              " ['at', 'the', 'first', 'signal', 'release', 'the'],\n",
              " ['catapults', '', 'we', 'll', 'use', 'the', 'cavalry', 'to'],\n",
              " ['cut', 'off', 'the', 'retreat', ''],\n",
              " ['general', '', 'i', 'do', 'nt', 'recommend', 'that', ''],\n",
              " ['our', 'cavalry', 'might', 'be', 'caught', 'in', 'the'],\n",
              " ['flames', ''],\n",
              " ['i', 'hope', 'not', '', 'because', 'i', 'm', 'going', 'to', 'be'],\n",
              " ['leading', 'them', ''],\n",
              " ['why', 'do', 'nt', 'they', 'know', 'they', 're', 'already'],\n",
              " ['dead', ''],\n",
              " ['now', ''],\n",
              " [],\n",
              " ['', 'to', 'his', 'men', ''],\n",
              " ['hold', 'steady', '', 'steady', ''],\n",
              " ['steady', ''],\n",
              " ['brothers', '', 'i', 'salute', 'you', '', 'for', 'rome', ''],\n",
              " ['caesar', ''],\n",
              " ['maximus', '', 'you', 'prove', 'your', 'valor', 'again', ''],\n",
              " ['let', 'us', 'hope', 'for', 'the', 'final', 'time', 'here', ''],\n",
              " ['i', 'do', 'nt', 'think', 'there', 's', 'anyone', 'left', 'to'],\n",
              " ['fight', ''],\n",
              " ['there', 'are', 'always', 'people', 'left', 'to'],\n",
              " ['fight', ''],\n",
              " ['but', 'this', 'night', '', 'at', 'least', '', 'germania'],\n",
              " ['is', 'at', 'last', 'defeated', '', 'what', 'will', 'you'],\n",
              " ['do', 'now', '', 'my', 'friend', ''],\n",
              " ['should', 'caesar', 'permit', '', 'i', 'll', 'go', 'home', ''],\n",
              " ['i', 've', 'been', 'away', 'too', 'long', '', 'i', 've'],\n",
              " ['forgotten', 'my', 'wife', 's', 'face', 'and', 'i'],\n",
              " ['barely', 'know', 'my', 'son', ''],\n",
              " [],\n",
              " ['', 'to', 'soldier', '']]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "sentences[0:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdGyfK56gvC6"
      },
      "outputs": [],
      "source": [
        "%load C99.py "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMSEHXnmpz1Z"
      },
      "outputs": [],
      "source": [
        " from C99 import C99"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVmTlM6Bpz1a"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('gladiator_sentence_transformer.pkl', 'rb') as f:\n",
        "    gladiator = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkRuv_-8pz1a"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaNc_xf0pz1a"
      },
      "outputs": [],
      "source": [
        "def encode_convs(profix):\n",
        "    model = C99(window = 4, std_coeff = 1)\n",
        "    sent_label = []\n",
        "    with open(profix+\"_sentence_transformer.pkl\", 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    for i in range(0, len(data)):\n",
        "        boundary = model.segment(data[i])\n",
        "        temp_labels = []\n",
        "        l = 0\n",
        "        for j in range(0, len(boundary)):\n",
        "            if boundary[j] == 1:\n",
        "                l += 1\n",
        "            temp_labels.append(l)\n",
        "        sent_label.append(temp_labels)\n",
        "    \n",
        "    with open(profix + '_sent_c99_label.pkl', 'wb') as f:\n",
        "        pickle.dump(sent_label, f)\n",
        "    \n",
        "    return sent_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7vod42Upz1b"
      },
      "outputs": [],
      "source": [
        "l = encode_convs('gladiator')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDUASObHpz1b"
      },
      "outputs": [],
      "source": [
        "l = encode_convs('val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_eq40Mtpz1b"
      },
      "outputs": [],
      "source": [
        "l = encode_convs('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpe1pqqYpz1b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT1av52Jpz1b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEap4zgvpz1c"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Topic_Segment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}